{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3883ea-4d92-4d72-b238-9431b3f1dc65",
   "metadata": {},
   "source": [
    "## VGG16 36 SPECIES MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57b5835-d905-4824-90ca-0920e1927c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280254e9-90d7-47ab-b812-ec1c710675e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/laurameyer/code/DSP-Tan/mushroom_learning/raw_data/3_12_mushroom_species_train_test/train\"\n",
    "path_test = \"/Users/laurameyer/code/DSP-Tan/mushroom_learning/raw_data/3_12_mushroom_species_train_test/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b68274f9-5e66-41f5-af65-4d08fd9f2a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4061"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_images_directory(directory):\n",
    "    data_dir = pathlib.Path(directory)\n",
    "    return data_dir \n",
    "\n",
    "data_dir = get_images_directory(path)\n",
    "data_dir_test = get_images_directory(path_test)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aee4778-6330-4ea2-9de4-a8adbaea351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "def load_training_data(data_dir):\n",
    "\n",
    "    return tf.keras.utils.image_dataset_from_directory(\n",
    "      data_dir,\n",
    "      labels='inferred',\n",
    "      validation_split=0.2,\n",
    "      subset=\"training\",\n",
    "      seed=123,\n",
    "      image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "      batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "def load_validation_data(data_dir):\n",
    "\n",
    "    return tf.keras.utils.image_dataset_from_directory(\n",
    "      data_dir,\n",
    "      labels='inferred',\n",
    "      validation_split=0.2,\n",
    "      subset=\"validation\",\n",
    "      seed=123,\n",
    "      image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "      batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "def load_testing_data(data_dir):\n",
    "    return tf.keras.utils.image_dataset_from_directory(\n",
    "      data_dir,\n",
    "      labels='inferred',\n",
    "      seed=123,\n",
    "      image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "      batch_size=BATCH_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a77ad01f-5015-45c3-9ba2-0ac84c505306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_from_tfdataset(tfdataset, batched=False):\n",
    "\n",
    "    labels = list(map(lambda x: x[1], tfdataset)) # Get labels \n",
    "\n",
    "    if not batched:\n",
    "        return tf.concat(labels, axis=0) # concat the list of batched labels\n",
    "\n",
    "    return labels\n",
    "\n",
    "def get_inputs_from_tfdataset(tfdataset, batched=False):\n",
    "\n",
    "    labels = list(map(lambda x: x[0], tfdataset)) # Get labels \n",
    "\n",
    "    if not batched:\n",
    "        return tf.concat(labels, axis=0) # concat the list of batched labels\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f00992c-b95f-4fc8-a5d9-2e7b0ec4c301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4071 files belonging to 13 classes.\n",
      "Using 3257 files for training.\n",
      "Found 4071 files belonging to 13 classes.\n",
      "Using 814 files for validation.\n",
      "Found 457 files belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_training_data(data_dir)\n",
    "val_ds = load_validation_data(data_dir)\n",
    "test_ds = load_testing_data(data_dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e31a71dc-9fab-43f4-875c-34a2c3fd7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation():\n",
    "\n",
    "        return keras.Sequential(\n",
    "        [\n",
    "            layers.RandomRotation(0.1),\n",
    "            layers.RandomZoom(0.1),\n",
    "        ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bfbe559-92dd-4847-8fac-2c1c0a8bab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = len(train_ds.class_names)\n",
    "\n",
    "def load_model():\n",
    "    return VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape, classes=num_classes, classifier_activation=\"softmax\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a461d76-56fe-4999-8a90-4f1aefd0c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nontrainable_layers(model):\n",
    "    \n",
    "    model.trainable = False\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8aecd88-d1e7-40b4-8f3a-c4411831b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def add_last_layers(model):\n",
    "    '''Take a pre-trained model, set its parameters as non-trainables, and add additional trainable layers on top'''\n",
    "    initializer = tf.keras.initializers.GlorotUniform(seed=0)\n",
    "    base_model = set_nontrainable_layers(model)\n",
    "    dropout_layer = layers.Dropout(0.2)\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer_1 = layers.Dense(50, activation='relu', kernel_initializer=initializer)\n",
    "    dense_layer_2 = layers.Dense(20, activation='relu', kernel_initializer=initializer)\n",
    "    prediction_layer = layers.Dense(num_classes, activation='softmax')\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        data_augmentation(),\n",
    "        layers.Rescaling(1./255),\n",
    "        base_model,\n",
    "        dropout_layer, \n",
    "        flatten_layer,\n",
    "        dense_layer_1,\n",
    "        dense_layer_2,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44126ce0-7892-4061-a0da-9056d2ee3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def build_model():\n",
    "        model = load_model()\n",
    "        model = add_last_layers(model)\n",
    "        \n",
    "        opt = optimizers.Adam(learning_rate=5e-4)\n",
    "        \n",
    "        model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    optimizer=opt,\n",
    "                    metrics=['accuracy'])\n",
    "        return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f1b2c-7fff-4bcc-b793-0d0b563be500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_accuracy', \n",
    "                   mode = 'max', \n",
    "                   patience = 5, \n",
    "                   verbose = 1, \n",
    "                   restore_best_weights = True)\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=epochs, \n",
    "                    verbose=1,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201073a0-05d9-45ae-ab08-424137dad4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../model_3_species_vgg16\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
